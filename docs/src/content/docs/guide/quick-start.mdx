---
title: Quick Start
description: Get up and running with UPP in minutes.
---

import { Tabs, TabItem, Steps, Aside } from '@astrojs/starlight/components';

# Quick Start

Get up and running with the Unified Provider Protocol in minutes.

## Installation

<Tabs>
  <TabItem label="npm">
    ```bash
    npm install @providerprotocol/ai
    ```
  </TabItem>
  <TabItem label="pnpm">
    ```bash
    pnpm add @providerprotocol/ai
    ```
  </TabItem>
  <TabItem label="bun">
    ```bash
    bun add @providerprotocol/ai
    ```
  </TabItem>
</Tabs>

## Your First LLM Call

<Steps>
1. **Import the library and a provider**

   ```typescript
   import { llm } from '@providerprotocol/ai';
   import { anthropic } from '@providerprotocol/ai/anthropic';
   ```

2. **Create an LLM instance**

   ```typescript
   const claude = llm({
     model: anthropic('claude-sonnet-4-20250514'),
     system: 'You are a helpful assistant.',
   });
   ```

3. **Generate a response**

   ```typescript
   const turn = await claude.generate('What is the capital of France?');
   console.log(turn.response.text);
   // "The capital of France is Paris."
   ```
</Steps>

<Aside type="tip" title="API Keys">
UPP automatically reads API keys from environment variables:
- `ANTHROPIC_API_KEY`
- `OPENAI_API_KEY`
- `GOOGLE_API_KEY`
- `OLLAMA_API_KEY` (optional)
- `OPENROUTER_API_KEY`
- `XAI_API_KEY`
</Aside>

## Streaming Responses

Stream tokens as they arrive:

```typescript
const stream = claude.stream('Write a haiku about coding.');

for await (const event of stream) {
  if (event.type === 'text_delta') {
    process.stdout.write(event.delta.text ?? '');
  }
}

// Get the complete turn after streaming
const turn = await stream.turn;
```

## Multi-Turn Conversations

Maintain conversation history:

```typescript
import { Message } from '@providerprotocol/ai';

const history: Message[] = [];

// First turn
const turn1 = await claude.generate(history, 'My name is Alice.');
history.push(...turn1.messages);

// Second turn - model remembers context
const turn2 = await claude.generate(history, 'What is my name?');
history.push(...turn2.messages);

console.log(turn2.response.text);
// "Your name is Alice."
```

## Using Different Providers

Switch providers by changing the import:

```typescript
import { llm } from '@providerprotocol/ai';
import { openai } from '@providerprotocol/ai/openai';
import { google } from '@providerprotocol/ai/google';
import { anthropic } from '@providerprotocol/ai/anthropic';

// OpenAI
const gpt = llm({ model: openai('gpt-4o') });

// Google
const gemini = llm({ model: google('gemini-2.0-flash') });

// Anthropic
const claude = llm({ model: anthropic('claude-sonnet-4-20250514') });
```

## Embeddings

Generate vector embeddings:

```typescript
import { embedding } from '@providerprotocol/ai';
import { openai } from '@providerprotocol/ai/openai';

const embedder = embedding({
  model: openai('text-embedding-3-small'),
});

const result = await embedder.embed('Hello, world!');
console.log(result.vector.length); // 1536
```

## Image Generation

Generate images from text:

```typescript
import { image } from '@providerprotocol/ai';
import { openai } from '@providerprotocol/ai/openai';

const dalle = image({
  model: openai('dall-e-3'),
  params: { size: '1024x1024' },
});

const result = await dalle.generate('A sunset over mountains');
const imageData = result.images[0].image.toBytes();
```

## Next Steps

- [Providers](/guide/providers) - All supported AI providers
- [Streaming](/guide/streaming) - Real-time response handling
- [Tools](/guide/tools) - Function calling
- [Conversations](/guide/conversations) - Managing chat history
- [Configuration](/guide/configuration) - API keys, retries, timeouts
