---
title: Turns
description: Understanding Turns - the result of LLM inference calls.
---

import { Aside } from '@astrojs/starlight/components';

# Turns

A `Turn` represents the complete result of one inference call, including all messages produced during tool execution loops.

## Turn Structure

```typescript
interface Turn<TData = unknown> {
  /**
   * All messages produced during this inference, in chronological order.
   * Types: UserMessage, AssistantMessage (may include toolCalls), ToolResultMessage
   */
  readonly messages: Message[];

  /** The final assistant response (convenience accessor) */
  readonly response: AssistantMessage;

  /** Tool executions that occurred during this turn */
  readonly toolExecutions: ToolExecution[];

  /** Aggregate token usage for the entire turn */
  readonly usage: TokenUsage;

  /** Total number of inference cycles (1 + number of tool rounds) */
  readonly cycles: number;

  /**
   * Structured output data (if structure was provided).
   * Type is inferred from the schema when using TypeScript.
   */
  readonly data?: TData;
}
```

## ToolExecution

Information about each tool execution during a turn:

```typescript
interface ToolExecution {
  /** The tool that was called */
  toolName: string;

  /** Tool call ID */
  toolCallId: string;

  /** Arguments passed to the tool */
  arguments: Record<string, unknown>;

  /** Result returned by the tool */
  result: unknown;

  /** Whether the tool execution resulted in an error */
  isError: boolean;

  /** Execution duration in milliseconds */
  duration: number;

  /** Whether approval was required and granted */
  approved?: boolean;
}
```

## TokenUsage

Aggregate token usage across all cycles:

```typescript
interface TokenUsage {
  /** Input tokens across all cycles */
  inputTokens: number;

  /** Output tokens across all cycles */
  outputTokens: number;

  /** Total tokens */
  totalTokens: number;

  /** Per-cycle breakdown (if available) */
  cycles?: Array<{
    inputTokens: number;
    outputTokens: number;
  }>;
}
```

## Turn with Tools

When tools are involved, a turn may contain multiple messages:

```typescript
const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  system: 'You are a helpful assistant.',
  tools: [getWeather],
});

const history: Message[] = [];

const turn = await claude.generate(history, 'What is the weather in Tokyo?');

// Turn contains ALL messages from this inference:
// 1. UserMessage: "What is the weather in Tokyo?"
// 2. AssistantMessage: { toolCalls: [{ toolName: 'getWeather', ... }] }
// 3. ToolResultMessage: [{ result: '72°F, sunny' }]
// 4. AssistantMessage: "The weather in Tokyo is 72°F and sunny!"

console.log(turn.messages.length);  // 4
console.log(turn.response.text);    // "The weather in Tokyo is 72°F and sunny!"
console.log(turn.toolExecutions);   // [{ toolName: 'getWeather', ... }]
console.log(turn.cycles);           // 2 (initial + after tool)

// Append all messages to history for next turn
history.push(...turn.messages);
```

## Turn Without Tools

When no tools are called, the turn is simpler:

```typescript
const turn = await claude.generate('Hello!');

console.log(turn.messages.length);       // 2
console.log(turn.messages[0].type);      // 'user'
console.log(turn.messages[1].type);      // 'assistant'
console.log(turn.response.text);         // "Hello! How can I help you today?"
console.log(turn.response.hasToolCalls); // false
console.log(turn.toolExecutions);        // []
console.log(turn.cycles);                // 1
```

## Turn with Structured Output

When using structured outputs, the parsed data is available:

```typescript
const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  structure: {
    type: 'object',
    properties: {
      name: { type: 'string' },
      age: { type: 'integer' },
    },
    required: ['name', 'age'],
  },
});

const turn = await claude.generate('John is 30 years old');

console.log(turn.data); // { name: 'John', age: 30 }
```

## Tool Execution Flow

The tool execution loop is managed by `llm()` core:

```
┌─────────────────────────────────────────────────────────────┐
│  llm.generate(history, input)                               │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────┐
│  1. Convert input to UserMessage                            │
│  2. Append to messages array                                │
└─────────────────────────────────────────────────────────────┘
                            │
                            ▼
              ┌─────────────────────────┐
              │  provider.complete()     │◄────────────────┐
              │  (single request)        │                 │
              └─────────────────────────┘                  │
                            │                              │
                            ▼                              │
              ┌─────────────────────────┐                  │
              │  response.hasToolCalls? │──── No ────┐     │
              └─────────────────────────┘            │     │
                            │                        │     │
                           Yes                       │     │
                            │                        │     │
                            ▼                        │     │
              ┌─────────────────────────┐            │     │
              │  Execute tools          │            │     │
              │  (parallel if multiple) │            │     │
              └─────────────────────────┘            │     │
                            │                        │     │
                            ▼                        │     │
              ┌─────────────────────────┐            │     │
              │  Append messages        │────────────┘     │
              │  to conversation        │──────────────────┘
              └─────────────────────────┘
                            │
                            ▼
                        Return Turn
```

<Aside type="note" title="Implementation Notes">
- Each cycle increments `Turn.cycles`
- Token usage is aggregated across all cycles
- All messages are collected in `Turn.messages`
- If `maxIterations` is reached, an error is thrown
- Tool execution order follows provider/model behavior
</Aside>
