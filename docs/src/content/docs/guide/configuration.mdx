---
title: Configuration
description: Configuring providers with API keys, retry strategies, and more.
---

import { Tabs, TabItem, Aside } from '@astrojs/starlight/components';

# Configuration

UPP provides flexible configuration options for provider infrastructure.

## ProviderConfig

All providers share a common configuration interface:

```typescript
interface ProviderConfig {
  /**
   * API key - string, async function, or key strategy
   * @example 'sk-xxx'
   * @example () => fetchKeyFromVault()
   * @example new RoundRobinKeys(['sk-1', 'sk-2'])
   */
  apiKey?: string | (() => string | Promise<string>) | KeyStrategy;

  /** Override the base API URL (for proxies, local models) */
  baseUrl?: string;

  /** Request timeout in milliseconds */
  timeout?: number;

  /** Custom fetch implementation (for logging, caching, custom TLS) */
  fetch?: typeof fetch;

  /** API version override */
  apiVersion?: string;

  /** Retry strategy for handling failures and rate limits */
  retryStrategy?: RetryStrategy;
}
```

### Provider-Specific Options

Some providers accept additional options for vendor-specific operational choices. These are passed to the **provider factory function**, not to `ProviderConfig`:

```typescript
interface OpenAIProviderOptions {
  /**
   * Which API to use:
   * - 'responses': Modern Responses API (default, recommended)
   * - 'completions': Legacy Chat Completions API
   */
  api?: 'responses' | 'completions';
}

// Use the modern Responses API (default)
const gpt = llm({
  model: openai('gpt-4o'),
});

// Explicitly use the legacy Completions API
const gptLegacy = llm({
  model: openai('gpt-4o', { api: 'completions' }),
});
```

<Aside type="note">
Provider options should be rare, well-documented, and have sensible defaults. Fundamentally different deployment targets (e.g., Vertex AI) should be separate providers, not options.
</Aside>

## API Key Configuration

<Tabs>
  <TabItem label="String">
```typescript
const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    apiKey: 'sk-ant-xxx',
  },
});
```
  </TabItem>
  <TabItem label="Environment Variable">
```typescript
const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    apiKey: process.env.ANTHROPIC_API_KEY,
  },
});
```
  </TabItem>
  <TabItem label="Async Function">
```typescript
const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    apiKey: async () => {
      const secret = await fetchFromVault('anthropic-key');
      return secret.value;
    },
  },
});
```
  </TabItem>
</Tabs>

<Aside type="tip">
If `apiKey` is not provided, UPP will automatically check standard environment variables:
- Anthropic: `ANTHROPIC_API_KEY`
- OpenAI: `OPENAI_API_KEY`
- Google: `GOOGLE_API_KEY`, `GEMINI_API_KEY`
- Stability: `STABILITY_API_KEY`
- Voyage: `VOYAGE_API_KEY`
</Aside>

## Key Strategies

UPP provides built-in key strategies for API key management:

### RoundRobinKeys

Cycles through a list of API keys:

```typescript
import { RoundRobinKeys } from '@providerprotocol/ai';

const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    apiKey: new RoundRobinKeys([
      process.env.ANTHROPIC_KEY_1!,
      process.env.ANTHROPIC_KEY_2!,
      process.env.ANTHROPIC_KEY_3!,
    ]),
  },
});
```

### WeightedKeys

Selects keys based on weight (useful for tiered pricing or rate limits):

```typescript
import { WeightedKeys } from '@providerprotocol/ai';

const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    apiKey: new WeightedKeys([
      { key: process.env.PRIMARY_KEY!, weight: 0.7 },
      { key: process.env.SECONDARY_KEY!, weight: 0.3 },
    ]),
  },
});
```

### DynamicKey

Custom key selection logic:

```typescript
import { DynamicKey } from '@providerprotocol/ai';

const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    apiKey: new DynamicKey(async () => {
      // Custom logic to select key
      const keys = await fetchActiveKeys();
      return selectLeastUsedKey(keys);
    }),
  },
});
```

## Retry Strategies

UPP provides pluggable retry strategies:

```typescript
interface RetryStrategy {
  /**
   * Called when a request fails with a retryable error.
   * @returns Delay in ms before retrying, or null to stop retrying
   */
  onRetry(error: UPPError, attempt: number): number | null | Promise<number | null>;

  /**
   * Called before each request. Can be used for pre-emptive rate limiting.
   */
  beforeRequest?(): number | Promise<number>;

  /**
   * Reset the strategy state (e.g., after a successful request)
   */
  reset?(): void;
}
```

### Built-in Strategies

```typescript
import {
  ExponentialBackoff,
  LinearBackoff,
  NoRetry,
  TokenBucket,
  RetryAfterStrategy,
} from '@providerprotocol/ai';

// Exponential backoff (recommended)
const strategy1 = new ExponentialBackoff({
  maxAttempts: 3,
  baseDelay: 1000,
  maxDelay: 30000,
});

// Linear backoff
const strategy2 = new LinearBackoff({
  maxAttempts: 5,
  delay: 2000,
});

// No retries
const strategy3 = new NoRetry();
```

### Custom Strategy

```typescript
class MyCustomStrategy implements RetryStrategy {
  onRetry(error: UPPError, attempt: number): number | null {
    if (attempt >= 5) return null; // Stop after 5 attempts

    // Wait longer for rate limits
    if (error.code === 'RATE_LIMITED') {
      return 5000;
    }

    return 1000; // Default 1 second
  }
}

const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    retryStrategy: new MyCustomStrategy(),
  },
});
```

## Base URL Override

Override the API endpoint for proxies or local models:

```typescript
const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    baseUrl: 'https://my-proxy.example.com',
  },
});
```

## Custom Fetch

Provide a custom fetch implementation for logging, caching, or custom TLS:

```typescript
const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    fetch: async (url, init) => {
      console.log('Request:', url);
      const response = await fetch(url, init);
      console.log('Response:', response.status);
      return response;
    },
  },
});
```

## Timeout Configuration

Set request timeout in milliseconds:

```typescript
const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    timeout: 30000, // 30 seconds
  },
});
```

## Full Configuration Example

```typescript
import { llm, RoundRobinKeys, ExponentialBackoff } from '@providerprotocol/ai';
import { anthropic } from '@providerprotocol/ai/anthropic';
import type { AnthropicLLMParams } from '@providerprotocol/ai/anthropic';

const claude = llm({
  model: anthropic('claude-sonnet-4-20250514'),
  config: {
    apiKey: new RoundRobinKeys([
      process.env.ANTHROPIC_KEY_1!,
      process.env.ANTHROPIC_KEY_2!,
    ]),
    baseUrl: 'https://my-proxy.example.com',
    timeout: 30000,
    retryStrategy: new ExponentialBackoff({ maxAttempts: 3 }),
  },
  params: {
    max_tokens: 4096,
    temperature: 0.7,
  } as AnthropicLLMParams,
  system: 'You are a helpful assistant.',
});
```
