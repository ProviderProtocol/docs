---
title: Specification Overview
description: UPP-1.2 Specification Overview - A language-agnostic protocol for AI inference services.
---

import { Aside, Badge, Card, CardGrid } from '@astrojs/starlight/components';

# UPP-1.2 Specification

<Badge text="Version 1.2.0-draft" variant="note" />
<Badge text="Status: Draft" variant="caution" />

The Unified Provider Protocol (UPP) is a language-agnostic specification for interacting with AI inference services. This document defines the protocol semantics, data structures, and implementation requirements for building UPP-compliant clients and providers in any programming language.

UPP establishes uniform interfaces for Large Language Models (LLM), Embedding Models, and Image Generation Models. The protocol enables multi-provider interoperability while preserving provider-native configuration and avoiding abstraction leakage.

UPP provides separate entry points for each modality—`llm()`, `embedding()`, `image()`—while sharing common provider infrastructure, configuration patterns, and design principles.

## Specification Status

The following table indicates the maturity level of each section in UPP 1.2:

| Section | Status | Notes |
|---------|--------|-------|
| **Core Architecture** | <Badge text="Stable" variant="success" size="small" /> | Provider model, configuration, entry points |
| **LLM Interface** | <Badge text="Stable" variant="success" size="small" /> | `llm()`, generate/stream, capabilities |
| **LLM Messages** | <Badge text="Stable" variant="success" size="small" /> | UserMessage, AssistantMessage, content blocks |
| **LLM Turns & Threads** | <Badge text="Stable" variant="success" size="small" /> | Turn structure, Thread utility |
| **LLM Streaming** | <Badge text="Stable" variant="success" size="small" /> | StreamResult, StreamEvent types |
| **LLM Tools** | <Badge text="Stable" variant="success" size="small" /> | Tool definition, execution loop, strategies |
| **LLM Structured Output** | <Badge text="Stable" variant="success" size="small" /> | JSON Schema constrained responses |
| **Embedding Interface** | <Badge text="Stable" variant="success" size="small" /> | `embedding()`, batch, similarity utilities |
| **Image Interface** | <Badge text="Stable" variant="success" size="small" /> | `image()`, generation, editing, variations |
| **Error Handling** | <Badge text="Stable" variant="success" size="small" /> | UPPError, error codes, retry strategies |
| **Provider Conformance** | <Badge text="Stable" variant="success" size="small" /> | Compliance levels, capability declaration |
| **Security Guidelines** | <Badge text="Stable" variant="success" size="small" /> | API keys, tool security, injection prevention |
| **Types & Schemas** | <Badge text="Stable" variant="success" size="small" /> | JSON Schema definitions |
| Audio Interface | <Badge text="Planned" variant="default" size="small" /> | Future: `audio()` for speech-to-text, TTS |
| Video Interface | <Badge text="Planned" variant="default" size="small" /> | Future: `video()` for video generation |

<Aside type="note" title="Draft Status">
  While individual sections are marked "Stable" to indicate they are complete and internally consistent, the overall specification remains in **Draft** status until 1.2.0 is finalized. Stable sections may still receive minor clarifications before the final release.
</Aside>

## Purpose

Modern AI development requires interacting with multiple providers (Anthropic, OpenAI, Google, Stability, Voyage, etc.), each with distinct APIs, authentication schemes, and response formats. UPP-1.2 establishes a standard protocol that:

- Provides modality-specific interfaces (`llm`, `embedding`, `image`)
- Enables provider switching without application code changes
- Maintains provider-native configuration to avoid abstraction leakage
- Shares common infrastructure (auth, retry, HTTP) across modalities
- Supports text, image, audio, video, embeddings, and future modalities

## Scope

This specification covers:

- The `llm()` function interface (chat/completion)
- The `embedding()` function interface (vector embeddings)
- The `image()` function interface (image generation)
- Provider adapter requirements for each modality
- Shared infrastructure (ProviderConfig, KeyStrategy, error handling)
- Message, Turn, and Thread data structures (LLM-specific)
- Streaming response handling
- Tool definition and execution

## Terminology

| Term | Definition |
|------|------------|
| **Provider** | A vendor-specific adapter exposing one or more modality interfaces |
| **Modality** | A distinct AI capability: LLM, embedding, image generation, etc. |
| **BoundModel** | A model instance bound to a specific provider and model ID |
| **Message** | A single message in an LLM conversation (user, assistant, or tool result) |
| **Turn** | The complete result of one LLM inference call, containing all messages produced |
| **StreamEvent** | A streaming event (lifecycle or content delta) |
| **Thread** | A utility class for managing LLM conversation history |
| **Embedding** | A vector representation of text or other content |
| **UPP** | Unified Provider Protocol |

## Requirements Language

The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this document are to be interpreted as described in [RFC 2119](https://www.rfc-editor.org/rfc/rfc2119).

## Modality Overview

| Entry Point | Purpose |
|-------------|---------|
| `llm()` | Chat, completion, reasoning |
| `embedding()` | Vector embeddings |
| `image()` | Image generation/editing |

Future modalities may include:
- `audio()` - Speech-to-text, text-to-speech
- `video()` - Video generation

## Notation Conventions

This specification uses language-agnostic pseudocode for examples. The pseudocode follows these conventions:

- Function calls: `function_name(arg1, arg2)`
- Object/map literals: `{key: value, key2: value2}`
- Array/list literals: `[item1, item2, item3]`
- Property access: `object.property`
- Method calls: `object.method(args)`
- Async operations: `await expression`
- Iteration: `for item in collection`
- Type annotations: `variable: Type`
- Optional values: `Type?` or `Optional&lt;Type&gt;`
- Comments: `// comment text`

## Code Examples

Code examples in this specification use the placeholder package name `upp`. Implementations MUST choose an appropriate package name for their ecosystem. Examples:

| Language | Example Package Name |
|----------|---------------------|
| JavaScript/TypeScript | `@upp/ai`, `unified-provider-protocol` |
| Python | `upp-ai`, `unified_provider_protocol` |
| Go | `github.com/org/upp` |
| Rust | `upp-protocol` |

Import syntax varies by language. Examples throughout this specification use JavaScript-style imports for readability:

```text
// Default export style
import anthropic from "upp/anthropic"

// Named export style
import { llm, embedding } from "upp"
```

Implementations SHOULD provide both styles where the language supports them. The semantic behavior is identical regardless of import syntax.

## What's Next?

<CardGrid>
  <Card title="Design Principles" icon="open-book">
    Learn about the [core principles](/upp/design-principles/) that guide UPP's design.
  </Card>
  <Card title="Architecture" icon="puzzle">
    Understand the [architecture](/upp/architecture/) and data flow.
  </Card>
  <Card title="LLM Interface" icon="rocket">
    Dive into the [LLM specification](/upp/llm/interface/).
  </Card>
  <Card title="Conformance" icon="approve-check">
    Review [conformance requirements](/upp/providers/conformance/) for providers.
  </Card>
</CardGrid>
