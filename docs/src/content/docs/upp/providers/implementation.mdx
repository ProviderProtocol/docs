---
title: Provider Implementation Guide
description: Guide for implementing UPP-compliant providers.
---

import { Aside, Badge, Card, CardGrid } from '@astrojs/starlight/components';

# Provider Implementation Guide

<Badge text="UPP-1.2.0" variant="note" />

## Provider Module Structure

Each provider module exports a single factory that combines all modality handlers:

```text
// Provider implementation structure

import { createProvider } from "upp"
import { createLLMHandler } from "./llm"
import { createEmbeddingHandler } from "./embed"
import { createImageHandler } from "./image"

openai = createProvider({
  name: "openai",
  version: "1.0.0",
  handlers: {
    llm: createLLMHandler(),
    embedding: createEmbeddingHandler(),
    image: createImageHandler()
  }
})

// Export provider and param types
export { openai }
export type { OpenAILLMParams, OpenAIEmbedParams, OpenAIImageParams }
```

## createProvider Helper

UPP implementations SHOULD provide a helper to create providers:

```text
function createProvider(options: CreateProviderOptions) -> Provider {
  provider = function(modelId: String) -> ModelReference {
    return { modelId: modelId, provider: provider }
  }

  provider.name = options.name
  provider.version = options.version
  registerHandlers(provider, options.handlers)

  return provider
}

CreateProviderOptions = {
  name: String,
  version: String,
  handlers: {
    llm: LLMHandler?,
    embedding: EmbeddingHandler?,
    image: ImageHandler?
  }
}
```

## HTTP-First Approach

Per Section 2.7 (HTTP-First Provider Implementation), providers SHOULD use direct HTTP calls rather than vendor SDKs.

## Shared Utilities

UPP implementations SHOULD provide utilities for provider implementations:

**resolveApiKey(config, envVar?) -> Promise&lt;String&gt;**

Resolve API key from ProviderConfig, supporting string, function, or KeyStrategy. If `config.apiKey` is not set, automatically falls back to standard environment variables. MUST throw `UPPError` with `AUTHENTICATION_FAILED` if no key is available.

**doFetch(url, init, config) -> Promise&lt;Response&gt;**

Execute fetch with retry, timeout, and error normalization. Uses `config.retryStrategy` for retry logic, `config.timeout` for request timeout, and `config.fetch` for custom fetch implementation. Automatically normalizes HTTP errors to `UPPError`.

**parseSSEStream(body) -> AsyncGenerator&lt;Any&gt;**

Parse Server-Sent Events stream into JSON objects. Handles standard SSE format with "data:" prefix. Yields parsed JSON for each event, terminates on "[DONE]" message.

**normalizeHttpError(response, provider, modality) -> Promise&lt;UPPError&gt;**

Normalize HTTP error responses to `UPPError`. Maps HTTP status codes to appropriate `ErrorCode` values. Extracts error message from response body when available.

## LLM Handler Pattern

```text
function createLLMHandler() -> LLMHandler {
  return {
    bind(modelId: String) -> BoundLLMModel {
      return {
        modelId: modelId,
        capabilities: {
          streaming: true,
          tools: true,
          structuredOutput: true,
          imageInput: true,
          videoInput: false,
          audioInput: false
        },

        complete: async (request) => {
          apiKey = await resolveApiKey(request.config, "VENDOR_API_KEY")

          // Transform UPP request to vendor format
          body = transformRequest(request, modelId)

          response = await doFetch(VENDOR_URL, {
            method: "POST",
            headers: { Authorization: "Bearer " + apiKey, ... },
            body: JSON.stringify(body)
          }, request.config)

          data = await response.json()

          // Transform vendor response to UPP format
          return transformResponse(data)
        },

        stream: (request) => {
          // Similar pattern with SSE parsing
          // Return LLMStreamResult (async iterator with response promise)
        }
      }
    }
  }
}
```

## Embedding Handler Pattern

Providers implement a single `embed()` method that handles batch requests. The `embedding()` core manages input normalization and chunked processing.

**OpenAI Example (Simple):**

```text
function createEmbeddingHandler() -> EmbeddingHandler {
  return {
    supportedInputs: ["text"],

    bind(modelId: String) -> BoundEmbeddingModel {
      return {
        modelId: modelId,
        maxBatchSize: 2048,
        maxInputLength: 8191,
        dimensions: 1536,

        embed: async (request) => {
          apiKey = await resolveApiKey(request.config, "OPENAI_API_KEY")

          // Pass params through unchanged to vendor API
          body = {
            model: modelId,
            input: request.inputs.map(i => typeof i == "string" ? i : i.text),
            ...request.params  // dimensions, encoding_format pass through
          }

          response = await doFetch(OPENAI_EMBEDDINGS_URL, {
            method: "POST",
            headers: { Authorization: "Bearer " + apiKey },
            body: JSON.stringify(body)
          }, request.config)

          data = await response.json()

          // Return EmbeddingResponse with metadata preserved
          // vector is List<Float> or base64 String depending on encoding_format
          return {
            embeddings: data.data.map(d => ({
              vector: d.embedding,  // floats or base64 string (core detects and decodes)
              index: d.index,
              tokens: null  // OpenAI doesn't report per-embedding tokens
            })),
            usage: { totalTokens: data.usage.total_tokens },
            metadata: {}  // OpenAI has no additional response metadata
          }
        }
      }
    }
  }
}
```

**Google Example (Complex with taskType):**

```text
function createGoogleEmbeddingHandler() -> EmbeddingHandler {
  return {
    supportedInputs: ["text", "image"],  // Google supports multimodal

    bind(modelId: String) -> BoundEmbeddingModel {
      return {
        modelId: modelId,
        maxBatchSize: 100,
        maxInputLength: 2048,
        dimensions: 3072,

        embed: async (request) => {
          apiKey = await resolveApiKey(request.config, "GOOGLE_API_KEY")

          // Transform to Google's batchEmbedContents format
          // Params (taskType, title, outputDimensionality) pass through
          body = {
            requests: request.inputs.map(input => ({
              model: "models/" + modelId,
              content: { parts: [{ text: typeof input == "string" ? input : input.text }] },
              taskType: request.params?.taskType,
              title: request.params?.title,
              outputDimensionality: request.params?.outputDimensionality
            }))
          }

          url = GOOGLE_API_URL + "/models/" + modelId + ":batchEmbedContents?key=" + apiKey

          response = await doFetch(url, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(body)
          }, request.config)

          data = await response.json()

          // Return EmbeddingResponse - preserve ALL metadata
          return {
            embeddings: data.embeddings.map((e, index) => ({
              vector: e.values,
              index: index,
              tokens: e.statistics?.tokenCount,
              // Per-embedding metadata (NOT redacted)
              metadata: {
                truncated: e.statistics?.truncated
              }
            })),
            usage: {
              totalTokens: data.embeddings.reduce((sum, e) => sum + (e.statistics?.tokenCount ?? 0), 0)
            },
            // Response-level metadata (NOT redacted)
            metadata: {
              safetyRatings: data.safetyRatings
            }
          }
        }
      }
    }
  }
}
```

**Key Implementation Notes:**

1. **Params pass-through:** Provider-specific parameters (`dimensions`, `taskType`, `encoding_format`, etc.) are passed through unchanged via `...request.params`
2. **Metadata preservation:** Providers MUST NOT discard provider-specific response data. Include it in `metadata` fields at both the embedding and response level
3. **Vector encoding:** The `vector` field can be `List&lt;Float&gt;` or a base64-encoded `String`. The `embedding()` core detects the type and normalizes to floats in the public result
4. **Providers without embeddings:** Providers that do not offer embedding APIs (e.g., Anthropic) simply omit the embedding handler when registering provider handlers (e.g., `createProvider({ handlers: { llm: ... } })`)

## Image Handler Pattern

```text
function createImageHandler() -> ImageHandler {
  return {
    bind(modelId: String) -> BoundImageModel {
      return {
        modelId: modelId,
        capabilities: {
          generate: true,
          streaming: false,
          edit: false,
          vary: false,
          upscale: false,
          outpaint: false,
          imageToImage: false,
          maxImages: 1,
          supportedSizes: ["1024x1024"],
          supportedFormats: ["png"]
        },

        generate: async (request) => {
          apiKey = await resolveApiKey(request.config, "VENDOR_API_KEY")

          body = {
            model: modelId,
            prompt: request.prompt,
            ...request.params
          }

          response = await doFetch(VENDOR_URL, {
            method: "POST",
            headers: { Authorization: "Bearer " + apiKey },
            body: JSON.stringify(body)
          }, request.config)

          data = await response.json()

          // Return ImageResponse
          return transformImageResponse(data)
        }

        // Implement edit, vary, upscale if capabilities indicate support
      }
    }
  }
}
```

## Key Implementation Requirements

1. **Request transformation:** Convert UPP `Message[]` to vendor message format
2. **Response transformation:** Convert vendor response to `LLMResponse`, `EmbeddingResponse`, or `ImageResponse`
3. **Error normalization:** Wrap vendor errors in `UPPError` with appropriate `ErrorCode` and `modality`
4. **Streaming:** Parse SSE streams and emit `StreamEvent` objects
5. **Metadata namespacing:** Store vendor-specific data under `metadata.{providerName}`

## Language-Specific Implementation Notes

#### Object-Oriented Languages (Java, C#, PHP)

```text
// Use interfaces/abstract classes for handlers
interface LLMHandler {
  BoundLLMModel bind(String modelId)
}

// Use classes for bound models
class OpenAIBoundLLMModel implements BoundLLMModel {
  String modelId
  LLMCapabilities capabilities

  LLMResponse complete(LLMRequest request)
  LLMStreamResult stream(LLMRequest request)
}
```

#### Systems Languages (Rust, Go)

```text
// Rust: Use traits
trait LLMHandler {
  fn bind(&self, model_id: &str) -> Box&lt;dyn BoundLLMModel&gt;;
}

// Go: Use interfaces
type LLMHandler interface {
  Bind(modelID string) BoundLLMModel
}
```

#### Dynamic Languages (Python, Ruby, JavaScript)

```text
// Use duck typing and factory functions
def create_llm_handler():
  def bind(model_id):
    return BoundLLMModel(model_id, ...)
  return {"bind": bind}
```